{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR,self).__init__()\n",
    "        self.fc = nn.Linear(24,2)\n",
    "    def forward(self,x):\n",
    "        out =  torch.sigmoid(self.fc(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/german.data-numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "标准化数据\n",
    "\"\"\"\n",
    "row,col = data.shape\n",
    "for c in range(col-1):\n",
    "    std = np.std(data[:,c])\n",
    "    mean = np.mean(data[:,c])\n",
    "    data[:,c] = (data[:,c] - mean) / std\n",
    "data[:,col-1] =  data[:,col-1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "x_train,x_test,y_train,y_test = data[:900,:24], data[900:,:24], data[:900,24], data[900:,24]\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "net = LR()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimier=torch.optim.Adam(net.parameters()) # Adam优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pred,lab):\n",
    "    t=pred.max(-1)[1]==lab\n",
    "    return torch.mean(t.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 24])\n"
     ]
    }
   ],
   "source": [
    "print(x_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7233, grad_fn=<NllLossBackward>) tensor(0.4200)\n",
      "tensor(0.6623, grad_fn=<NllLossBackward>) tensor(0.6700)\n",
      "tensor(0.6253, grad_fn=<NllLossBackward>) tensor(0.7100)\n",
      "tensor(0.6037, grad_fn=<NllLossBackward>) tensor(0.7100)\n",
      "tensor(0.5894, grad_fn=<NllLossBackward>) tensor(0.7400)\n",
      "tensor(0.5790, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5710, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5646, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5593, grad_fn=<NllLossBackward>) tensor(0.7200)\n",
      "tensor(0.5549, grad_fn=<NllLossBackward>) tensor(0.7200)\n",
      "tensor(0.5512, grad_fn=<NllLossBackward>) tensor(0.7200)\n",
      "tensor(0.5479, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5451, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5425, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5403, grad_fn=<NllLossBackward>) tensor(0.7400)\n",
      "tensor(0.5383, grad_fn=<NllLossBackward>) tensor(0.7400)\n",
      "tensor(0.5365, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5348, grad_fn=<NllLossBackward>) tensor(0.7300)\n",
      "tensor(0.5333, grad_fn=<NllLossBackward>) tensor(0.7400)\n",
      "tensor(0.5320, grad_fn=<NllLossBackward>) tensor(0.7400)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    # print(criterion())\n",
    "    net.train()\n",
    "    y_hat = net(x_train)\n",
    "   \n",
    "    loss=criterion(y_hat,y_train)\n",
    "    \n",
    "    optimier.zero_grad()\n",
    "    loss.backward()\n",
    "    optimier.step()\n",
    "    \n",
    "    if i % 100  == 0:\n",
    "#         net.eval()\n",
    "        print(loss,test(net(x_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于eval 和 train的解释\n",
    "+ 使用PyTorch进行训练和测试时一定注意要把实例化的model指定train/eval，eval（）时，框架会自动把BN和DropOut固定住，不会取平均，而是用训练好的值，不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
