{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKT condition\n",
    "2019-07-14 暂时的理解,根据[Mit-KKT](https://ocw.mit.edu/courses/mechanical-engineering/2-854-introduction-to-manufacturing-systems-fall-2016/lecture-notes/MIT2_854F16_KktExample.pdf) 以及 [西瓜书](https://blog.csdn.net/lcdxshengpeng/article/details/88570215)\n",
    "对于这样的一个带约束的优化问题:\n",
    "$$min\\;f(x)$$\n",
    "$$s.t.\\;g(x)\\geq 0$$\n",
    "可以将问题分为两种情况：<br>\n",
    "1. $g(x)=0,Boundary\\;solution$,当存在边界解的时候，那么最优的解应当相切。\n",
    "2. $g(x)<0,Interior\\;solution$，当存在内部解的时候,也就是__最优解在区域内部的时候__（注意是存在内部解，也就是说最优解是在$g(x)<0$的范围内的；一定注意是存在，如果不存在，那么问题就和1相同了，下图很好地反应了相应的结果）。\n",
    "<img src=\"./image/KTT.png\" style=\"zoom:60%\">\n",
    "总结：<font color = 'red'>如果最优解$x^*$在约束的条件内，那么约束条件就无效，因为直接求导取零得到的解直接满足相应条件；如果最优解不再约束条件内，那么边界$g(x)=0$的约束条件会使得最优解被限制在边界上。</font>\n",
    "\n",
    "\n",
    "## SMO algorithm for SVM\n",
    "根据KKT以及一般问题的推导，SVM的问题被转换为,这是一个关于$\\alpha$的优化问题[SMO推导](https://www.cnblogs.com/pinard/p/6111471.html)：\n",
    "$$\\begin{matrix}\n",
    "max_{\\alpha} & \\sum_{i=1}^{m} \\alpha_{i} - \\frac {1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}y^{(i)}y^{(j)}\\alpha_i\\alpha_j \\left \\langle x_{i},x_{j} \\right \\rangle\\\\ \n",
    "subject\\;to  & \\begin{matrix}\n",
    "0 \\leq \\alpha_i \\leq C\n",
    "\\\\ \n",
    "\\sum_{i=1}^{m} \\alpha_iy^{{i}}=0\\end{matrix}\n",
    "\\end{matrix}$$\n",
    "\n",
    "\n",
    "## Kernel Method\n",
    "1. $基础概念$\n",
    "    1. $ 特征变换: feature\\;mapping$\n",
    "    $$\\phi:\\; R^{2}\\rightarrow R^{3}$$\n",
    "    2. $ 源空间X和特征空间H$\n",
    "    3. $将数据embedding到一个向量空间，寻求一个线性决策边界。map选择合适的话，问题会被简化。$\n",
    "\n",
    "2. $实例$\n",
    "    1. 源空间包含是一个被椭圆边界划分的数据，特征空间的数据可以被超平面划分。\n",
    "    $$\\phi:\\; （x_{1},x_{2}）\\rightarrow (z_{1},z_{2},z_{3})=(x^{2}_{1},\\sqrt{2}x_{1}x_{2},x^2_{2})$$\n",
    "    2. 公式展开：\n",
    "    $$<\\phi(x_{1},x_{2}),\\phi(x^{'}_{1},x^{'}_{2})> = <(z_{1},z_{2},z_{3}),(z^{'}_{1},z^{'}_{2},z^{'}_{3})>$$\n",
    "    $$= <(x^{2}_{1},\\sqrt{2}x_{1}x_{2},x^2_{2}),(x^{'2}_{1},\\sqrt{2}x^{'}_{1}x^{'}_{2},x^{'2}_{2})>$$\n",
    "    $$= x^{2}_{1}x^{'2}_{1} + 2x_{1}x_{2}x^{'}_{1}x^{'}_{2} + x^{2}_{2}x^{'2}_{2}$$\n",
    "    $$=(<x,x^{'}>)^{2}$$\n",
    "    $$=k(x,x^{'})，称为多项式核$$\n",
    "    3. 注意映射函数和核函数并不是一个概念。\n",
    "    4. feture空间上的距离和内积也可以用kernel function表示。\n",
    "    5. Kernel Matrix 所有元素的含义是所有点在feature space的内积的矩阵。\n",
    "\n",
    "3. 深层次的理解<br>\n",
    "    + 核函数时一种表示__后表示方法__，也就是说假设存在一个映射关系$\\phi$,这种映射关系将数据转换到了高纬度的空间，而数据在高纬空间中的内积可以直接用核函数进行表示,核函数:$k(x_i,x_j)$,\n",
    "映射函数:$\\phi$<br>\n",
    "    + 核函数是两种形式的表示方法，一种是直接将源空间的数据映射到高维空间中进行内积运算；另一种是给出一种封闭的算式，它可以直接表示在高维空间进行内积运算后的结果。\n",
    "    $$k(x_i,x_j) = \\left\\{\\begin{matrix}\n",
    "\\phi {(x_i)}\\phi {(x_j)}\n",
    "\\\\ \n",
    "exp(-\\frac{\\|x_i-x_j\\|^2} {2\\sigma^2})\n",
    "\\end{matrix}\\right. $$\n",
    "\n",
    "4. 常见核函数 <br>\n",
    "线性核：$$k(x,{x}')= x^Tx$$\n",
    "多项式核:$$k(x,{x}') = (x^Tx + c)^d $$\n",
    "高斯核:$$k(x,{x}') = exp(-\\frac{\\|x_i-x_j\\|^2} {2\\sigma^2}) = exp(-\\lambda  \\|x_i-x_j\\|^2)$$\n",
    "在高斯核中，当$\\sigma$值越大或者说$\\lambda$越小时，SVM决策边界平滑和简单，容易欠拟合<br>\n",
    "在高斯核中，当$\\sigma$值越小或者说$\\lambda$越大时，SVM决策边界复杂，容易过拟合\n",
    "对于这种现象的解释[link](http://haohanw.blogspot.com/2014/03/ml-how-sigma-matters-in-svm-rbf-kernel.html)\n",
    "\n",
    "5. 一些常见表达方式：\n",
    "对于核函数$K$，<br>\n",
    "    + 用$K(X,Y)$\n",
    "    $$K(X,Y)表示两个向量之间的K，是一个标量，scalar$$\n",
    "    + 用$K(\\cdot,\\cdot )$\n",
    "    $$K(\\cdot,\\cdot)表示一个无穷维度的矩阵$$\n",
    "    + 用$K(X,\\cdot )$\n",
    "       $$K(X,\\cdot)表示矩阵的X行$$\n",
    "\n",
    "## 正定矩阵和半正定矩阵\n",
    "1. 半正定矩阵（positive semi-definite matrix）\n",
    "$$X^{T}MX\\geq0$$\n",
    "可以将$M$看成是一个变换矩阵，可以得到：\n",
    "$$Y=MX$$\n",
    "那么，实际上述表示可以转换为：\n",
    "$$X^{T}Y\\geq0$$\n",
    "某一种理解：\n",
    "$$cos(\\theta)=\\frac{X^{T}Y}{\\|X\\|*\\|Y\\|}$$\n",
    "因此半正定矩阵可以理解为一个向量记过它的变换后向量与其本身的夹角小于90度\n",
    "2. 正定矩阵被包括在半正定矩阵中\n",
    "$$X^{T}MX > 0$$\n",
    "3. <font color = 'red'>如何将正定矩阵与核函数有效结合在一起？？？</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 最简单的SMO算法\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def foo(x,y):\n",
    "    return x*x + y*y + x*y\n",
    "x = 0.4\n",
    "y = 0.5\n",
    "m = 5\n",
    "j = 0\n",
    "while j < 1000:\n",
    "    for i in range(m):\n",
    "        x = x - 0.01 * (2 * x + y)\n",
    "    for i in range(m):\n",
    "        y = y - 0.01 * (2 * y + x)\n",
    "    \n",
    "    j = j + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
