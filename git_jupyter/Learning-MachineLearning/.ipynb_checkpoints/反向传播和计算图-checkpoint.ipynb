{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算图\n",
    "\n",
    "## 正向传播\n",
    "正向传播时对神经网络从输入层到输出层的顺序，<font color='red'>依次计算并存储模型的中间变量</font>，包括输出，不考虑偏差项，那么中间变量可以表示为：\n",
    "$$\\textbf z = \\textbf{W} \\textbf{x}$$\n",
    "\n",
    "## 反向传播\n",
    "反向传播时指的是神经网络参数梯度的方法，沿着输出层到输入层的顺序，依次计算并存储__目标函数__有关神经网络各层的__中间变量__以及__参数的梯度__\n",
    "### softmax的反向传播\n",
    "$$损失函数：L(y,p) = -\\sum_{i=1}^{C} y_i\\;log(p_i),\\;p_i=\\frac {exp(a_i)} {\\sum exp(a)}$$\n",
    "$$求L关于a_j的导数：\\frac {\\partial L} {\\partial a_j}=\\frac {\\partial  -\\sum_{i=1}^{C} y_i\\;log(p_i)} {\\partial a_j}$$\n",
    "$$\\frac {\\partial L} {\\partial a_i}=  -\\sum_{i=1}^{C} y_i \\frac {\\partial log(p_i)} {\\partial a_i}$$\n",
    "$$\\frac {\\partial L} {\\partial a_i}=  -\\sum_{i=1}^{C} \\frac {y_i} {p_i} \\frac {\\partial p_i} {\\partial a_j}$$\n",
    "而对于$\\frac {\\partial p_i} {\\partial a_j}$考虑两种情况，$i=j\\;\\&\\;i\\neq j$\n",
    "1. $i=j\\;时，求出的结果是：$\n",
    "$$\\frac {\\partial p_i} {\\partial a_j}= p_i(1-p_j) $$\n",
    "2. $i \\neq j\\;时，求出的结果是：$\n",
    "$$\\frac {\\partial p_i} {\\partial a_j}= p_i*p_j $$\n",
    "\n",
    "代入上式，得到：\n",
    "$$\\frac {\\partial L} {\\partial a_i}=  -\\sum_{i=1}^{C} \\frac {y_i} {p_i}[p_i(1-p_j) +  p_i*p_j]$$\n",
    "\n",
    "## 正向传播和反响传播相互依赖\n",
    "__一方面__，正向传播的计算可能依赖于模型参数的当前值，而这些模型参数是在反向传播的梯度计算后通过优化算法迭代的,<br>\n",
    "__另一方面__，反向传播的梯度计算可能依赖于各变量的当前值，而这些变量的当前值是通过正向传播计算得到的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
